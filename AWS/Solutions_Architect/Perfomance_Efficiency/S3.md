## Sections

- [S3 Guarantees]
- [Charges]
- [Free Tier]
- [Storage Tiers]
- [Versioning]
- [Security]
- [Subresources]
- [URLs]
- [Logging]


## Links

https://aws.amazon.com/s3/pricing/

https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html

https://aws.amazon.com/s3/faqs/

https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html

https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html

By default, you can create up to 100 buckets in an AWS account, and that is a limit that AWS does not override without officially requesting for a service limit increase.

Strong Consistency a.k.a. Read after write consistency of PUTS of new objects
Eventual Consistency for overwrite PUTS and DELETES (i.e. can take time to propogate)

S3 is Region scoped and can not replicate data across regions

# S3 Standard Guarantees

* Built for 99.99% availability
* Amazon guarantees 99.9% availability (.09% / 1 nine less than what it was built for)
* Amazon guarantees 99.999999999% for durability of S3 information (Remember 11 nines!)


# Charges

## General
* Storage
* Requests and Data Retrieval
* Data Transfer
* Management and Replication

## Specific
* Transfer in is free
* Transfer out to another S3 or to CloudFront is also free


# Free Tier

New AWS customers receive 5GB of Amazon S3 storage in the S3 Standard storage class; 20,000 GET Requests; 2,000 PUT, COPY, POST, or LIST Requests; and 15GB of Data Transfer Out each month for one year.


# Storage Tiers / Classes
### S3 Standard

General purpose storage for any type of data, typically used for frequently accessed data.

* Cheaper retrieval but more expensive storage

    First 50 TB / Month	$0.023 per GB
    Next 450 TB / Month	$0.022 per GB
    Over 500 TB / Month	$0.021 per GB

### S3 - IA (Infrequently accessed)

For long lived but infrequently accessed data that needs millisecond access.

* Cheaper storage, but more expensive retreival
* 30 day storage minimum
* The minimum object size is 0 bytes, however you will be billed for 128 KB. Objects smaller that 128 can still be stored, but will be billed as if they are 128KB.

    All Storage / Month	$0.0125 per GB

### Intelligent Tiering

Automatic cost savings for data with unknown or changing access patterns.

    Frequent Access Tier, First 50 TB / Month	$0.023 per GB
    Frequent Access Tier, Next 450 TB / Month	$0.022 per GB
    Frequent Access Tier, Over 500 TB / Month	$0.021 per GB
    Infrequent Access Tier, All Storage / Month	$0.0125 per GB
    Monitoring and Automation, All Storage / Month	$0.0025 per 1,000 objects

### S3 One Zone - IA

For re-createable infrequently accessed data that needs millisecond access

    All Storage / Month	$0.01 per GB

### S3 Glacier

For long-term backups and archives with retrieval option from 1 minute to 12 hours.
Encrpyts data by default.
Regional availabilty
11 nines for durability

## Retrieval Types:
### Expedited
For all but the largest archives (250MB+), data accessed using Expedited retrievals are typically made available within 1 – 5 minutes.

Expedited retrievals are priced at a flat rate of $0.03 per GB and $0.01 per request.

There are two types of Expedited retrievals: On-Demand and Provisioned. On-Demand requests are fulfilled when we are able to complete the retrieval within 1 – 5 minutes. Provisioned requests ensure that retrieval capacity for Expedited retrievals is available when you need them.
### Standard
Standard retrievals typically complete within 3 – 5 hours.
Standard retrievals are priced at a flat rate of $0.01 per GB and $0.05 per 1,000 requests.
### Bulk
Bulk retrievals are S3 Glacier’s lowest-cost retrieval option, enabling you to retrieve petabytes of data inexpensively in a day. Bulk retrievals typically complete within 5 – 12 hours.
Bulk retrievals are priced at a flat rate of just $0.0025 per GB and $0.025 per 1,000 requests.

    All Storage / Month	$0.004 per GB

### S3 Glacier Deep Archive

For long-term data archiving that is accessed once or twice in a year and can be restored within 12 hours

    All Storage / Month	$0.00099 per GB



# Versioning

Versioning in S3 is similar to version control in GitHub. S3 will save every version of an object such that it can be retrieved, restored, or deleted.

* Stores all versions of an object (including all writes and even if you delete an object).

* Once enabled, versioning can not be disabled, only suspended.

* Integrates with lifecycle rules.

* MFA can be used as a requirement for deleting versions (i.e. versioning's "MFA Delete" capability).

* Deleting the default version (i.e. by not specifying) will create a "Delete marker", this must be deleted in order to actually delete that specific version.

* Not all versions of each object are visible by default in the S3 console, the "Show" version tab must be selected (can be used to address specific versions, such as deleting, restoring, etc).

# Lifecylce Management

You can create "Lifecycle rules" for a bucket that will automate moving objects in the bucket into different storage tiers. 
Lifecylce rules can used in conjuction with versioning whereby you can apply differnet rules between current and previous versions for objects.
Rules can be applied to objects that match a certain key prefix/tags or the entire bucket.

# Security

By default, all S3 Buckets are private. You must manully uncheck "Block Public Access" during / after creation in the "Set Permissions" tab to enable public access.

S3 Buckets can be configured to create access logs which are capable of being sent to other buckets (even buckets in another account).

### Bucket Policies

### Encryption in Transit

Encrypts data as it's moving between servers.
* SSL/TLS.

### Encryption at Rest (Server Side)

* S3 Managed Keys - SSE-S3
* AWS Key Management Service, Managed Keys - SSE-KMS
* Server Side Encryption with Customer Provided Keys - SSE-C

### Encryption at Rest (Client Side)

* KMS managed master encyrption keys Management CSE-KMS
* Customer managed master encyrption keys CSE-C

## S3 Object Locks

## Glacier Valut Locks

# Prefixes

A bucket prefix is essentially the object's path minus the bucket name and object name (e.g. mybucket/redb/data.csv = redb, mybucket/redb/access/prcl.mdb = redb/access)

# Sharing Buckets Across Accounts

There are three ways to share buckets across accounts:
* Bucket Access Control Lists (Programmatic-Objects only)
* Bucket Policies and IAM (Programmatic-Bucket Level)
* Cross Account IAM Roles (Programmatic and Console)

# Cross Region Replication

* Requires versioning to be enabled (for source and sink).
* Only objects updated after replication was enabled with be replicated / mirrored.
* Will not replicate delete markers nor specfic object versions.

*Technically, objects can be replcaited within the same region.*

# Transfer Acceleration

Transfer Acceleration takes advantage of Amazon CloudFront’s globally distributed edge locations. As the data arrives at an edge location, data is routed to Amazon S3 over an optimized network path.

You might want to use Transfer Acceleration on a bucket for various reasons, including the following:

* You have customers that upload to a centralized bucket from all over the world.

* You transfer gigabytes to terabytes of data on a regular basis across continents.

* You are unable to utilize all of your available bandwidth over the Internet when uploading to Amazon S3.

https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html

# URLs
The Virtual Hosted Style URL, the Path-Style Access URL, the Static web site URL, and the Legacy Global Endpoint URL.

## Virtual Hosted

bucket.s3.amazonaws.com
bucket.s3-aws-region.amazonaws.com

## Path-Style
s3.Region.amazonaws.com/bucket/key

# Logging

### Server access logging
Server access logging is what you should enable to record and get information on the requests made to the company’s S3 buckets. 

### Object-level logging
You choose object-level logging for recording object-level API activity using AWS CloudTrail, which comes with a cost.

# Subresources

### Access Control List

### Torents

Requester Pays, S3 Events???

retrieval options??? bulk, nearline, etc...

Multipart Upload API for all objects???

*Until 2018 there was a hard limit on S3 puts of 100 PUTs per second. To achieve this care needed to be taken with the structure of the name Key to ensure parallel processing. As of July 2018 the limit was raised to 3500 and the need for the Key design was basically eliminated. Disk IOPS is not the issue with the problem. The account limit is not the issue with the problem.*???   NANI!!!!




